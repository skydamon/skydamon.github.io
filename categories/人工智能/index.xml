<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>人工智能 on 胡刘郏的技术博客</title>
    <link>https://www.huliujia.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/</link>
    <description>Recent content in 人工智能 on 胡刘郏的技术博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 14 Mar 2020 22:01:26 +0800</lastBuildDate>
    
	<atom:link href="https://www.huliujia.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>学习笔记：相似度度量与协同过滤</title>
      <link>https://www.huliujia.com/blog/7255c95b81e55827c1b8e6cbf24f2f760c978e06/</link>
      <pubDate>Sat, 14 Mar 2020 22:01:26 +0800</pubDate>
      
      <guid>https://www.huliujia.com/blog/7255c95b81e55827c1b8e6cbf24f2f760c978e06/</guid>
      <description>相似度度量 相似度度量关注的是两个对象是否相似，相似程度是多少？比如两张图片、两篇文章、两句话、两个人的喜好的相抵程度等。 为了度量相似度，首先需要将比较对象转换成实数向量，这样计算机才能够理解。对象类型不同，转换方式也不同，最终目的都是将比较对象转换成实数向</description>
    </item>
    
    <item>
      <title>学习笔记：信息熵与决策树</title>
      <link>https://www.huliujia.com/blog/ebab9bd78f525f25a01ef64345f279977c78a75f/</link>
      <pubDate>Mon, 09 Mar 2020 23:03:40 +0800</pubDate>
      
      <guid>https://www.huliujia.com/blog/ebab9bd78f525f25a01ef64345f279977c78a75f/</guid>
      <description>信息熵 什么是信息熵 信息熵用于度量”预测随机变量Y的取值“的难度。信息熵越大说明Y的取值的不确定性越大，即预测难度越大。本文用H(Y)表示预测Y值的信息熵。 下表为两只球队的虚拟的胜、负、平历史记录，显然预测恒大比赛结果的难度要远小于绿城。因为恒大90%都是胜</description>
    </item>
    
  </channel>
</rss>