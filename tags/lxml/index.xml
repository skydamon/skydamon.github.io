<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>lxml on 胡刘郏的技术博客</title>
    <link>https://www.huliujia.com/tags/lxml/</link>
    <description>Recent content in lxml on 胡刘郏的技术博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 26 Sep 2019 23:41:47 +0800</lastBuildDate>
    
	<atom:link href="https://www.huliujia.com/tags/lxml/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Pyhon&#43;lxml&#43;xpath快速实现网页爬虫（比BeautifulSoup好用）</title>
      <link>https://www.huliujia.com/blog/70f98f7c0ea538497afde194f6af34ea4cee3738/</link>
      <pubDate>Thu, 26 Sep 2019 23:41:47 +0800</pubDate>
      
      <guid>https://www.huliujia.com/blog/70f98f7c0ea538497afde194f6af34ea4cee3738/</guid>
      <description>背景 最近因为工作需要写爬虫，以前用过BeautifulSoup，所以很自然的无脑上BeautifulSoup了，不过使用过程中发现BeautifulSoup有一个致命的缺陷，就是不能支持XPath。XPath可以快速在结构化的文档（如XML，HTML）中查</description>
    </item>
    
    <item>
      <title>使用lxml.etree解析中文网页时出现乱码问题的解决办法</title>
      <link>https://www.huliujia.com/blog/7ed51f3056b97ed75a998eee93082bb957756ccd/</link>
      <pubDate>Mon, 23 Sep 2019 23:38:19 +0800</pubDate>
      
      <guid>https://www.huliujia.com/blog/7ed51f3056b97ed75a998eee93082bb957756ccd/</guid>
      <description>吐槽 不得不说网络这个东西害死人，一群只会复制粘贴的瓜皮儿。 没一点有用的答案，还要写的像模像样装x 这个问题折腾了一个晚上，晚上找了各种方案，都是相互抄，然而都不能解决问题，找的过程中看到一个博主发出了这样的感慨，真的深表赞同啊，鱼目混杂的内容太多了。 lxml.etree.tostring 乱码的</description>
    </item>
    
  </channel>
</rss>